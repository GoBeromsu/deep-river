{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Example for anomaly detection with LSTM autoencoder architectures\n",
    "\n",
    "There is a multitude of successful architecture. In the following we demonstrate the implementation of 3 possible architecture types.\n",
    "\n",
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T08:14:15.458963Z",
     "iopub.status.busy": "2024-06-16T08:14:15.458646Z",
     "iopub.status.idle": "2024-06-16T08:14:17.497000Z",
     "shell.execute_reply": "2024-06-16T08:14:17.496401Z"
    }
   },
   "outputs": [],
   "source": [
    "from river import compose, preprocessing, metrics, datasets\n",
    "\n",
    "from deep_river.anomaly import RollingAutoencoder\n",
    "from torch import nn, manual_seed\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](sutskever_ae.png)\n",
    "\n",
    "LSTM Encoder-Decoder architecture by Sutskever et al. 2014 (https://arxiv.org/abs/1409.3215). The decoder only gets access to its own prediction of the previous timestep. Decoding also takes performed backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T08:14:17.514062Z",
     "iopub.status.busy": "2024-06-16T08:14:17.513880Z",
     "iopub.status.idle": "2024-06-16T08:14:17.521130Z",
     "shell.execute_reply": "2024-06-16T08:14:17.520685Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size,\n",
    "        hidden_size,\n",
    "        sequence_length=None,\n",
    "        predict_backward=True,\n",
    "        num_layers=1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.cell = nn.LSTMCell(input_size, hidden_size)\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.predict_backward = predict_backward\n",
    "        self.sequence_length = sequence_length\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = (\n",
    "            None\n",
    "            if num_layers <= 1\n",
    "            else nn.LSTM(\n",
    "                input_size=hidden_size,\n",
    "                hidden_size=hidden_size,\n",
    "                num_layers=num_layers - 1,\n",
    "            )\n",
    "        )\n",
    "        self.linear = (\n",
    "            None\n",
    "            if input_size == hidden_size\n",
    "            else nn.Linear(hidden_size, input_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, h, sequence_length=None):\n",
    "        \"\"\"Computes the forward pass.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x:\n",
    "            Input of shape (batch_size, input_size)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tuple[torch.Tensor, Tuple[torch.Tensor, torch.Tensor]]\n",
    "            Decoder outputs (output, (h, c)) where output has the shape (sequence_length, batch_size, input_size).\n",
    "        \"\"\"\n",
    "\n",
    "        if sequence_length is None:\n",
    "            sequence_length = self.sequence_length\n",
    "        x_hat = torch.empty(sequence_length, h.shape[0], self.hidden_size)\n",
    "        for t in range(sequence_length):\n",
    "            if t == 0:\n",
    "                h, c = self.cell(h)\n",
    "            else:\n",
    "                input = h if self.linear is None else self.linear(h)\n",
    "                h, c = self.cell(input, (h, c))\n",
    "            t_predicted = -t if self.predict_backward else t\n",
    "            x_hat[t_predicted] = h\n",
    "\n",
    "        if self.lstm is not None:\n",
    "            x_hat = self.lstm(x_hat)\n",
    "\n",
    "        return x_hat, (h, c)\n",
    "\n",
    "\n",
    "class LSTMAutoencoderSutskever(nn.Module):\n",
    "    def __init__(self, n_features, hidden_size=30, n_layers=1):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        self.encoder = nn.LSTM(\n",
    "            input_size=n_features, hidden_size=hidden_size, num_layers=n_layers\n",
    "        )\n",
    "        self.decoder = LSTMDecoder(\n",
    "            input_size=hidden_size,\n",
    "            hidden_size=n_features,\n",
    "            predict_backward=True,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        _, (h, _) = self.encoder(x)\n",
    "        x_hat, _ = self.decoder(h[-1], x.shape[0])\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "The models can be tested with the code in the following cells. Since River currently does not feature any anomaly detection datasets with temporal dependencies, the results should be expected to be somewhat inaccurate.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T08:14:17.523375Z",
     "iopub.status.busy": "2024-06-16T08:14:17.523221Z",
     "iopub.status.idle": "2024-06-16T08:14:17.528401Z",
     "shell.execute_reply": "2024-06-16T08:14:17.528019Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = manual_seed(42)\n",
    "dataset = datasets.CreditCard().take(5000)\n",
    "metric = metrics.ROCAUC(n_thresholds=50)\n",
    "\n",
    "module = LSTMAutoencoderSutskever  # Set this variable to your architecture of choice\n",
    "ae = RollingAutoencoder(module=module, lr=0.005)\n",
    "scaler = preprocessing.StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-16T08:14:17.530642Z",
     "iopub.status.busy": "2024-06-16T08:14:17.530458Z",
     "iopub.status.idle": "2024-06-16T08:14:30.070021Z",
     "shell.execute_reply": "2024-06-16T08:14:30.069185Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (-1) isn't allowed in a leading, non-existing dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m scaler\u001b[38;5;241m.\u001b[39mlearn_one(x)\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mtransform_one(x)\n\u001b[0;32m----> 4\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mae\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m metric\u001b[38;5;241m.\u001b[39mupdate(y_true\u001b[38;5;241m=\u001b[39my, y_pred\u001b[38;5;241m=\u001b[39mscore)\n\u001b[1;32m      6\u001b[0m ae\u001b[38;5;241m.\u001b[39mlearn_one(x\u001b[38;5;241m=\u001b[39mx, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/Research/deep-river/deep_river/anomaly/rolling_ae.py:203\u001b[0m, in \u001b[0;36mRollingAutoencoder.score_one\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_initialized:\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_features\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(x)\n\u001b[0;32m--> 203\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_window) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwindow_size:\n\u001b[1;32m    206\u001b[0m     x_win \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_x_window\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[0;32m~/Documents/Research/deep-river/deep_river/base.py:134\u001b[0m, in \u001b[0;36mDeepEstimator.initialize_module\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer_fn(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_initialized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_input_output_layers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Research/deep-river/deep_river/base.py:179\u001b[0m, in \u001b[0;36mDeepEstimator._get_input_output_layers\u001b[0;34m(self, n_features)\u001b[0m\n\u001b[1;32m    176\u001b[0m apply_hooks(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, hook\u001b[38;5;241m=\u001b[39mtracker, handles\u001b[38;5;241m=\u001b[39mhandles)\n\u001b[1;32m    178\u001b[0m x_dummy \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;241m1\u001b[39m, n_features), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 179\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_dummy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m handles:\n\u001b[1;32m    182\u001b[0m     h\u001b[38;5;241m.\u001b[39mremove()\n",
      "File \u001b[0;32m~/miniconda3/envs/deepriver/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/deepriver/lib/python3.10/site-packages/torch/nn/modules/module.py:1561\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1558\u001b[0m     bw_hook \u001b[38;5;241m=\u001b[39m hooks\u001b[38;5;241m.\u001b[39mBackwardHook(\u001b[38;5;28mself\u001b[39m, full_backward_hooks, backward_pre_hooks)\n\u001b[1;32m   1559\u001b[0m     args \u001b[38;5;241m=\u001b[39m bw_hook\u001b[38;5;241m.\u001b[39msetup_input_hook(args)\n\u001b[0;32m-> 1561\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks:\n\u001b[1;32m   1563\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook_id, hook \u001b[38;5;129;01min\u001b[39;00m (\n\u001b[1;32m   1564\u001b[0m         \u001b[38;5;241m*\u001b[39m_global_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1565\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mitems(),\n\u001b[1;32m   1566\u001b[0m     ):\n\u001b[1;32m   1567\u001b[0m         \u001b[38;5;66;03m# mark that always called hook is run\u001b[39;00m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mLSTMAutoencoderCho.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     22\u001b[0m _, (h, _) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(x)\n\u001b[1;32m     23\u001b[0m target_shape \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     24\u001b[0m     (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_first \u001b[38;5;28;01melse\u001b[39;00m (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mh\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m x_hat, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(h)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x_hat\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (-1) isn't allowed in a leading, non-existing dimension 1"
     ]
    }
   ],
   "source": [
    "for x, y in tqdm(list(dataset)):\n",
    "    scaler.learn_one(x)\n",
    "    x = scaler.transform_one(x)\n",
    "    score = ae.score_one(x)\n",
    "    metric.update(y_true=y, y_pred=score)\n",
    "    ae.learn_one(x=x, y=None)\n",
    "print(f\"ROCAUC: {metric.get():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deepriver')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "588c5aed37ac83ab820db8800694f2ee474f3b87874329a77c5b9c85c1eac9fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
