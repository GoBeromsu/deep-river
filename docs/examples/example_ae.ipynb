{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'river_torch.anomaly' has no attribute 'AnomalyDetector' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lucascazzonelli/Documents/Research/river-torch/docs/examples/example_ae.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucascazzonelli/Documents/Research/river-torch/docs/examples/example_ae.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mriver\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, metrics\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lucascazzonelli/Documents/Research/river-torch/docs/examples/example_ae.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mriver_torch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manomaly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn_builder\u001b[39;00m \u001b[39mimport\u001b[39;00m get_fc_encoder, get_fc_decoder\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucascazzonelli/Documents/Research/river-torch/docs/examples/example_ae.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mriver_torch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manomaly\u001b[39;00m \u001b[39mimport\u001b[39;00m Autoencoder\n",
      "File \u001b[0;32m~/Documents/Research/river-torch/river_torch/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m anomaly, classification, regression, utils\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m__version__\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m      4\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39manomaly\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mregression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mutils\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Research/river-torch/river_torch/anomaly/__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrolling_ae\u001b[39;00m \u001b[39mimport\u001b[39;00m RollingWindowAutoencoder\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m Autoencoder\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mscaler\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     StandardScaler,\n\u001b[1;32m      9\u001b[0m     MeanScaler,\n\u001b[1;32m     10\u001b[0m     MinMaxScaler,\n\u001b[1;32m     11\u001b[0m     RollingStandardScaler,\n\u001b[1;32m     12\u001b[0m     AdaptiveStandardScaler,\n\u001b[1;32m     13\u001b[0m     RollingMinMaxScaler,\n\u001b[1;32m     14\u001b[0m     RollingMeanScaler,\n\u001b[1;32m     15\u001b[0m     AdaptiveMeanScaler,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     19\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAutoencoder\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mVariationalAutoencoder\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAdaptiveMeanScaler\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/Research/river-torch/river_torch/anomaly/scaler.py:105\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m         score \u001b[39m=\u001b[39m raw_score \u001b[39m/\u001b[39m mean\n\u001b[1;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m score\n\u001b[0;32m--> 105\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMinMaxScaler\u001b[39;00m(AnomalyScaler):\n\u001b[1;32m    106\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, anomaly_detector: anomaly\u001b[39m.\u001b[39mAnomalyDetector):\n\u001b[1;32m    107\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(anomaly_detector)\n",
      "File \u001b[0;32m~/Documents/Research/river-torch/river_torch/anomaly/scaler.py:106\u001b[0m, in \u001b[0;36mMinMaxScaler\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMinMaxScaler\u001b[39;00m(AnomalyScaler):\n\u001b[0;32m--> 106\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, anomaly_detector: anomaly\u001b[39m.\u001b[39;49mAnomalyDetector):\n\u001b[1;32m    107\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(anomaly_detector)\n\u001b[1;32m    108\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin \u001b[39m=\u001b[39m Min()\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'river_torch.anomaly' has no attribute 'AnomalyDetector' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from river import datasets, metrics\n",
    "from river_torch.anomaly.nn_builder import get_fc_encoder, get_fc_decoder\n",
    "from river_torch.anomaly import Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "river_torch.anomaly.nn_builder.get_fc_encoder() got multiple values for keyword argument 'n_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m model \u001b[38;5;241m=\u001b[39m AutoencodedAnomalyDetector(encoder_fn\u001b[38;5;241m=\u001b[39mencoder_fn,decoder_fn\u001b[38;5;241m=\u001b[39mdecoder_fn, lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, n_features\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x,y \u001b[38;5;129;01min\u001b[39;00m dataset:\n\u001b[0;32m----> 9\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscore_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     metric\u001b[38;5;241m.\u001b[39mupdate(y_true\u001b[38;5;241m=\u001b[39my, y_pred\u001b[38;5;241m=\u001b[39mscore)\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m.\u001b[39mlearn_one(x\u001b[38;5;241m=\u001b[39mx)\n",
      "File \u001b[0;32m~/Documents/projects/IncrementalLearning/river-torch/river_torch/base.py:314\u001b[0m, in \u001b[0;36mAutoencodedAnomalyDetector.score_one\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    311\u001b[0m x \u001b[38;5;241m=\u001b[39m dict2tensor(x, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 314\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_features\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39minference_mode():\n",
      "File \u001b[0;32m~/Documents/projects/IncrementalLearning/river-torch/river_torch/base.py:350\u001b[0m, in \u001b[0;36mAutoencodedAnomalyDetector._init_net\u001b[0;34m(self, n_features)\u001b[0m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_init_net\u001b[39m(\u001b[38;5;28mself\u001b[39m, n_features):\n\u001b[0;32m--> 350\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_fn(\n\u001b[1;32m    351\u001b[0m         n_features\u001b[38;5;241m=\u001b[39mn_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder_fn)\n\u001b[1;32m    352\u001b[0m     )\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_fn(\n\u001b[1;32m    354\u001b[0m         n_features\u001b[38;5;241m=\u001b[39mn_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_args(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder_fn)\n\u001b[1;32m    355\u001b[0m     )\n\u001b[1;32m    357\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mTypeError\u001b[0m: river_torch.anomaly.nn_builder.get_fc_encoder() got multiple values for keyword argument 'n_features'"
     ]
    }
   ],
   "source": [
    "encoder_fn = get_fc_encoder\n",
    "decoder_fn = get_fc_decoder\n",
    "dataset = datasets.CreditCard().take(5000)\n",
    "metric = metrics.ROCAUC()\n",
    "\n",
    "model = Autoencoder(encoder_fn=encoder_fn,decoder_fn=decoder_fn, lr=0.01, n_features=5)\n",
    "\n",
    "for x,y in dataset:\n",
    "    score = model.score_one(x)\n",
    "    metric.update(y_true=y, y_pred=score)\n",
    "    model.learn_one(x=x)\n",
    "print(f'ROCAUC: {metric.get()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deepriver')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "588c5aed37ac83ab820db8800694f2ee474f3b87874329a77c5b9c85c1eac9fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
