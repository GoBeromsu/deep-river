{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'river_torch.anomaly' has no attribute 'AnomalyDetector' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/lucascazzonelli/Documents/Research/river-torch/docs/examples/example_ae.ipynb Cell 1'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucascazzonelli/Documents/Research/river-torch/docs/examples/example_ae.ipynb#ch0000000?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mriver\u001b[39;00m \u001b[39mimport\u001b[39;00m datasets, metrics\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/lucascazzonelli/Documents/Research/river-torch/docs/examples/example_ae.ipynb#ch0000000?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mriver_torch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manomaly\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn_builder\u001b[39;00m \u001b[39mimport\u001b[39;00m get_fc_encoder, get_fc_decoder\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/lucascazzonelli/Documents/Research/river-torch/docs/examples/example_ae.ipynb#ch0000000?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mriver_torch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39manomaly\u001b[39;00m \u001b[39mimport\u001b[39;00m Autoencoder\n",
      "File \u001b[0;32m~/Documents/Research/river-torch/river_torch/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m anomaly, classification, regression, utils\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m__version__\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m      4\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39manomaly\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mregression\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mutils\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Documents/Research/river-torch/river_torch/anomaly/__init__.py:7\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mrolling_ae\u001b[39;00m \u001b[39mimport\u001b[39;00m RollingWindowAutoencoder\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m Autoencoder\n\u001b[0;32m----> 7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mscaler\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m      8\u001b[0m     StandardScaler,\n\u001b[1;32m      9\u001b[0m     MeanScaler,\n\u001b[1;32m     10\u001b[0m     MinMaxScaler,\n\u001b[1;32m     11\u001b[0m     RollingStandardScaler,\n\u001b[1;32m     12\u001b[0m     AdaptiveStandardScaler,\n\u001b[1;32m     13\u001b[0m     RollingMinMaxScaler,\n\u001b[1;32m     14\u001b[0m     RollingMeanScaler,\n\u001b[1;32m     15\u001b[0m     AdaptiveMeanScaler,\n\u001b[1;32m     16\u001b[0m )\n\u001b[1;32m     18\u001b[0m __all__ \u001b[39m=\u001b[39m [\n\u001b[1;32m     19\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAutoencoder\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mVariationalAutoencoder\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mAdaptiveMeanScaler\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     32\u001b[0m ]\n",
      "File \u001b[0;32m~/Documents/Research/river-torch/river_torch/anomaly/scaler.py:105\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    100\u001b[0m         score \u001b[39m=\u001b[39m raw_score \u001b[39m/\u001b[39m mean\n\u001b[1;32m    102\u001b[0m         \u001b[39mreturn\u001b[39;00m score\n\u001b[0;32m--> 105\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMinMaxScaler\u001b[39;00m(AnomalyScaler):\n\u001b[1;32m    106\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, anomaly_detector: anomaly\u001b[39m.\u001b[39mAnomalyDetector):\n\u001b[1;32m    107\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(anomaly_detector)\n",
      "File \u001b[0;32m~/Documents/Research/river-torch/river_torch/anomaly/scaler.py:106\u001b[0m, in \u001b[0;36mMinMaxScaler\u001b[0;34m()\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMinMaxScaler\u001b[39;00m(AnomalyScaler):\n\u001b[0;32m--> 106\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, anomaly_detector: anomaly\u001b[39m.\u001b[39;49mAnomalyDetector):\n\u001b[1;32m    107\u001b[0m         \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(anomaly_detector)\n\u001b[1;32m    108\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin \u001b[39m=\u001b[39m Min()\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'river_torch.anomaly' has no attribute 'AnomalyDetector' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "from river import datasets, metrics\n",
    "from river_torch.anomaly.nn_builder import get_fc_encoder, get_fc_decoder\n",
    "from river_torch.anomaly import AutoEncoder"
   ]
  },
  {
   "cell_type": "code",
     ]
    }
   ],
   "source": [
    "encoder_fn = get_fc_encoder\n",
    "decoder_fn = get_fc_decoder\n",
    "dataset = datasets.CreditCard().take(5000)\n",
    "metric = metrics.ROCAUC()\n",
    "\n",
    "model = Autoencoder(encoder_fn=encoder_fn,decoder_fn=decoder_fn, lr=0.01, n_features=5)\n",
    "\n",
    "for x,y in dataset:\n",
    "    score = model.score_one(x)\n",
    "    metric.update(y_true=y, y_pred=score)\n",
    "    model.learn_one(x=x)\n",
    "print(f'ROCAUC: {metric.get()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('deepriver')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "588c5aed37ac83ab820db8800694f2ee474f3b87874329a77c5b9c85c1eac9fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
