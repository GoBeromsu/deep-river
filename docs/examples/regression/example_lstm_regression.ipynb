{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# LSTM Regression Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "from river_torch.regression import RollingRegressor\n",
    "from river import metrics, compose, preprocessing\n",
    "from river.datasets import Bikes\n",
    "from torch import nn\n",
    "from tqdm import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "class MyModule(nn.Module):\n",
    "\n",
    "    def __init__(self, n_features, hidden_size=1):\n",
    "        super().__init__()\n",
    "        self.n_features=n_features\n",
    "        self.hidden_size = hidden_size\n",
    "        self.lstm = nn.LSTM(input_size=n_features, hidden_size=hidden_size, num_layers=1)\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        output, (hn, cn) = self.lstm(X)  # lstm with input, hidden, and internal state\n",
    "        hn = hn.view(-1, self.hidden_size)\n",
    "        return self.softmax(hn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "Pipeline (\n  Select (\n    clouds\n    humidity\n    pressure\n    temperature\n    wind\n  ),\n  StandardScaler (\n    with_std=True\n  ),\n  RollingRegressor (\n    module=<class '__main__.MyModule'>\n    loss_fn=\"mse_loss\"\n    optimizer_fn=<class 'torch.optim.sgd.SGD'>\n    lr=0.01\n    window_size=20\n    append_predict=True\n    device=\"cpu\"\n    seed=42\n  )\n)",
      "text/html": "<div><div class=\"river-component river-pipeline\"><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">['clouds', 'humidity', 'pressure', 'temperature', 'wind']</pre></summary><code class=\"river-estimator-params\">\n{'keys': {'pressure', 'humidity', 'temperature', 'wind', 'clouds'}}\n\n</code></details><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">StandardScaler</pre></summary><code class=\"river-estimator-params\">\n{'counts': Counter(),\n 'means': defaultdict(&lt;class 'float'&gt;, {}),\n 'vars': defaultdict(&lt;class 'float'&gt;, {}),\n 'with_std': True}\n\n</code></details><details class=\"river-component river-estimator\"><summary class=\"river-summary\"><pre class=\"river-estimator-name\">RollingRegressor</pre></summary><code class=\"river-estimator-params\">\n{'_batch_i': 0,\n '_x_window': deque([], maxlen=20),\n 'append_predict': True,\n 'device': 'cpu',\n 'kwargs': {'hidden_size': 1},\n 'loss_fn': &lt;function mse_loss at 0x0000029531D88D30&gt;,\n 'lr': 0.01,\n 'module': &lt;class '__main__.MyModule'&gt;,\n 'module_initialized': False,\n 'optimizer_fn': &lt;class 'torch.optim.sgd.SGD'&gt;,\n 'seed': 42,\n 'window_size': 20}\n\n</code></details></div><style scoped>\n.river-estimator {\n    padding: 1em;\n    border-style: solid;\n    background: white;\n}\n\n.river-pipeline {\n    display: flex;\n    flex-direction: column;\n    align-items: center;\n    background: linear-gradient(#000, #000) no-repeat center / 3px 100%;\n}\n\n.river-union {\n    display: flex;\n    flex-direction: row;\n    align-items: center;\n    justify-content: center;\n    padding: 1em;\n    border-style: solid;\n    background: white\n}\n\n.river-wrapper {\n    display: flex;\n    flex-direction: column;\n    align-items: center;\n    justify-content: center;\n    padding: 1em;\n    border-style: solid;\n    background: white;\n}\n\n.river-wrapper > .river-estimator {\n    margin-top: 1em;\n}\n\n/* Vertical spacing between steps */\n\n.river-component + .river-component {\n    margin-top: 2em;\n}\n\n.river-union > .river-estimator {\n    margin-top: 0;\n}\n\n.river-union > .pipeline {\n    margin-top: 0;\n}\n\n/* Spacing within a union of estimators */\n\n.river-union > .river-component + .river-component {\n    margin-left: 1em;\n}\n\n/* Typography */\n\n.river-estimator-params {\n    display: block;\n    white-space: pre-wrap;\n    font-size: 120%;\n    margin-bottom: -1em;\n}\n\n.river-estimator > .river-estimator-params,\n.river-wrapper > .river-details > river-estimator-params {\n    background-color: white !important;\n}\n\n.river-estimator-name {\n    display: inline;\n    margin: 0;\n    font-size: 130%;\n}\n\n/* Toggle */\n\n.river-summary {\n    display: flex;\n    align-items:center;\n    cursor: pointer;\n}\n\n.river-summary > div {\n    width: 100%;\n}\n</style></div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Bikes()\n",
    "metric = metrics.MAE()\n",
    "\n",
    "model_pipeline = compose.Select('clouds', 'humidity', 'pressure', 'temperature', 'wind')\n",
    "model_pipeline |= preprocessing.StandardScaler()\n",
    "model_pipeline |= RollingRegressor(\n",
    "    module=MyModule,\n",
    "    loss_fn='mse',\n",
    "    optimizer_fn='sgd',\n",
    "    window_size=20,\n",
    "    lr=1e-2,\n",
    "    hidden_size=1,  # parameters of MyModule can be overwritten\n",
    "    append_predict=True,\n",
    ")\n",
    "model_pipeline"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "257it [00:03, 74.56it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m model_pipeline\u001B[38;5;241m.\u001B[39mpredict_one(x)\n\u001B[0;32m      3\u001B[0m     metric \u001B[38;5;241m=\u001B[39m metric\u001B[38;5;241m.\u001B[39mupdate(y_true\u001B[38;5;241m=\u001B[39my, y_pred\u001B[38;5;241m=\u001B[39my_pred)\n\u001B[1;32m----> 4\u001B[0m     model_pipeline \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_pipeline\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlearn_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMAE: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmetric\u001B[38;5;241m.\u001B[39mget()\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[1;32m~\\Documents\\environments\\river-torch\\lib\\site-packages\\river\\compose\\pipeline.py:524\u001B[0m, in \u001B[0;36mPipeline.learn_one\u001B[1;34m(self, x, y, **params)\u001B[0m\n\u001B[0;32m    522\u001B[0m last_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(steps)\n\u001B[0;32m    523\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m last_step\u001B[38;5;241m.\u001B[39m_supervised:\n\u001B[1;32m--> 524\u001B[0m     last_step\u001B[38;5;241m.\u001B[39mlearn_one(x\u001B[38;5;241m=\u001B[39mx, y\u001B[38;5;241m=\u001B[39my, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n\u001B[0;32m    525\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    526\u001B[0m     last_step\u001B[38;5;241m.\u001B[39mlearn_one(x, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mparams)\n",
      "File \u001B[1;32m~\\Documents\\projects\\IncrementalLearning\\river-torch\\river_torch\\regression\\rolling_regressor.py:162\u001B[0m, in \u001B[0;36mRollingRegressor.learn_one\u001B[1;34m(self, x, y)\u001B[0m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m x \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    161\u001B[0m     y \u001B[38;5;241m=\u001B[39m float2tensor(y, device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m--> 162\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_learn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    164\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[1;32m~\\Documents\\projects\\IncrementalLearning\\river-torch\\river_torch\\regression\\rolling_regressor.py:168\u001B[0m, in \u001B[0;36mRollingRegressor._learn\u001B[1;34m(self, x, y)\u001B[0m\n\u001B[0;32m    166\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_learn\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: torch\u001B[38;5;241m.\u001B[39mTensor, y: torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m--> 168\u001B[0m     y_pred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    169\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn(y_pred, y)\n\u001B[0;32m    170\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()\n",
      "File \u001B[1;32m~\\Documents\\environments\\river-torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36mMyModule.forward\u001B[1;34m(self, X, **kwargs)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, X, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m---> 11\u001B[0m     output, (hn, cn) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# lstm with input, hidden, and internal state\u001B[39;00m\n\u001B[0;32m     12\u001B[0m     hn \u001B[38;5;241m=\u001B[39m hn\u001B[38;5;241m.\u001B[39mview(\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhidden_size)\n\u001B[0;32m     13\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msoftmax(hn)\n",
      "File \u001B[1;32m~\\Documents\\environments\\river-torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\Documents\\environments\\river-torch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:769\u001B[0m, in \u001B[0;36mLSTM.forward\u001B[1;34m(self, input, hx)\u001B[0m\n\u001B[0;32m    767\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_forward_args(\u001B[38;5;28minput\u001B[39m, hx, batch_sizes)\n\u001B[0;32m    768\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 769\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43m_VF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlstm\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    770\u001B[0m \u001B[43m                      \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbatch_first\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    771\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    772\u001B[0m     result \u001B[38;5;241m=\u001B[39m _VF\u001B[38;5;241m.\u001B[39mlstm(\u001B[38;5;28minput\u001B[39m, batch_sizes, hx, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_flat_weights, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias,\n\u001B[0;32m    773\u001B[0m                       \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_layers, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdropout, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtraining, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbidirectional)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for x, y in tqdm(dataset.take(5000)):\n",
    "    y_pred = model_pipeline.predict_one(x)\n",
    "    metric = metric.update(y_true=y, y_pred=y_pred)\n",
    "    model_pipeline = model_pipeline.learn_one(x=x, y=y)\n",
    "print(f'MAE: {metric.get():.2f}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}